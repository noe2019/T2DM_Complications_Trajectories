{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set display option for debugging purposes\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Read the excel file\n",
    "df = pd.read_excel(\"data/feuille11.xlsx\")\n",
    "\n",
    "# Create a regex pattern to match the codes\n",
    "code_pattern = '|'.join([\"E11.2\", \"E11.3\", \"E11.4\", \"E11.5\", \"L97\"])\n",
    "\n",
    "# Filter rows where either column contains any of the codes\n",
    "df_filtered = df[\n",
    "    df[\"Code Dx Principal\"].str.contains(code_pattern) |\n",
    "    df[\"Ecle Me Cim  Diagnostic (Autres)\"].str.contains(code_pattern)\n",
    "]\n",
    "\n",
    "# Function to replace non-matching codes with NaN\n",
    "def replace_codes(series, pattern):\n",
    "    return series.where(series.str.contains(pattern), other=pd.NA)\n",
    "\n",
    "# Replace the codes in both columns\n",
    "df_filtered[\"Code Dx Principal\"] = replace_codes(df_filtered[\"Code Dx Principal\"], code_pattern)\n",
    "df_filtered[\"Ecle Me Cim  Diagnostic (Autres)\"] = replace_codes(df_filtered[\"Ecle Me Cim  Diagnostic (Autres)\"], code_pattern)\n",
    "\n",
    "# Convert 'Dt Admission' to datetime\n",
    "df_filtered['Dt Admission'] = pd.to_datetime(df_filtered['Dt  Admission'])\n",
    "\n",
    "# Sort the dataframe by patient ID and admission date\n",
    "df_sorted = df_filtered.sort_values(['PatienId', 'Dt  Admission'])\n",
    "\n",
    "# Add a visit number for each patient ID and admission date combination\n",
    "df_sorted['Visit_Number'] = df_sorted.groupby(['PatienId', 'Dt  Admission']).cumcount() + 1\n",
    "\n",
    "# Pivot the dataframe with the additional Visit_Number to ensure uniqueness\n",
    "df_pivot_principal = df_sorted.pivot(index='PatienId', columns=['Dt  Admission', 'Visit_Number'], values='Code Dx Principal')\n",
    "df_pivot_secondary = df_sorted.pivot(index='PatienId', columns=['Dt  Admission', 'Visit_Number'], values='Ecle Me Cim  Diagnostic (Autres)')\n",
    "\n",
    "# Concatenate the pivoted dataframes and align them with the patient IDs\n",
    "df_pivot = pd.concat([df_pivot_principal, df_pivot_secondary], axis=1, keys=['Principal', 'Secondary'])\n",
    "\n",
    "# Flatten the MultiIndex columns by joining the level values into one string\n",
    "new_columns = [\n",
    "    f'{level0}_{level1.date()}_{level2}' \n",
    "    for (level0, level1, level2) in zip(\n",
    "        df_pivot.columns.get_level_values(0), \n",
    "        df_pivot.columns.get_level_values(1), \n",
    "        df_pivot.columns.get_level_values(2)\n",
    "    )\n",
    "]\n",
    "\n",
    "df_pivot.columns = new_columns\n",
    "\n",
    "# Define a function to extract date and visit number from the column name\n",
    "def extract_date_visit(col_name):\n",
    "    parts = col_name.split('_')\n",
    "    # Extract the date and visit number\n",
    "    date_part = parts[1]  # '2023-01-01'\n",
    "    visit_part = parts[2]  # 'visit1'\n",
    "    # Convert to datetime and int for sorting\n",
    "    date = pd.to_datetime(date_part)\n",
    "    visit_number = int(visit_part)#.replace('visit', ''))\n",
    "    return date, visit_number\n",
    "\n",
    "# Sort the columns using the custom key function\n",
    "sorted_columns = sorted(df_pivot.columns, key=extract_date_visit)\n",
    "\n",
    "# Reindex the DataFrame with the sorted columns\n",
    "df_pivot_sorted = df_pivot[sorted_columns]\n",
    "\n",
    "# Create column lists\n",
    "\n",
    "t3 = []\n",
    "t4 = []\n",
    "for col_name in df_pivot_sorted.columns:\n",
    "    \n",
    "    parts = col_name.split('_')\n",
    "    # Extract the date and visit number\n",
    "    \n",
    "    t3.append('Principal_'+parts[1]+'_'+parts[2])  # '2023-01-01'\n",
    "    t4.append('Secondary_'+parts[1]+'_'+parts[2])\n",
    "\n",
    "# Filter only relevant columns to reduce memory usage\n",
    "relevant_columns = t3 + t4\n",
    "df_optimized = df_pivot_sorted[relevant_columns]\n",
    "\n",
    "\n",
    "# Convert all the relevant columns to string type to avoid type mismatch issues\n",
    "df_optimized[t3 + t4] = df_optimized[t3 + t4].astype(str)\n",
    "\n",
    "\n",
    "l = ['E11.2','E11.3','E11.4','E11.5','L97']\n",
    "\n",
    "\n",
    "def process_row(row):\n",
    "    v0 = []\n",
    "    for j in t3:\n",
    "        code_principal = row[j]\n",
    "        code_secondary = row[j.replace('Principal', 'Secondary')]\n",
    "        \n",
    "        # Check for the conditions as per the original script\n",
    "        if code_principal in l and code_secondary in l:\n",
    "            if code_principal != code_secondary and code_principal not in v0 and code_secondary not in v0:\n",
    "                v0.extend([code_principal, code_secondary])\n",
    "            elif code_principal == code_secondary and code_principal not in v0:\n",
    "                v0.append(code_principal)\n",
    "        elif code_principal in l and code_principal not in v0:\n",
    "            v0.append(code_principal)\n",
    "        elif code_secondary in l and code_secondary not in v0:\n",
    "            v0.append(code_secondary)\n",
    "\n",
    "    return v0\n",
    "def process_row1(row):\n",
    "    v0 = []\n",
    "    for j in t3:\n",
    "        code_principal = row[j]\n",
    "        code_secondary = row[j.replace('Principal', 'Secondary')]\n",
    "        \n",
    "        # Check for the conditions as per the original script\n",
    "        if code_principal in l and code_secondary in l:\n",
    "            if code_principal != code_secondary and code_principal not in v0 and code_secondary not in v0:\n",
    "                v0.extend([code_secondary,code_principal])\n",
    "            elif code_principal == code_secondary and code_principal not in v0:\n",
    "                v0.append(code_principal)\n",
    "        elif code_principal in l and code_principal not in v0:\n",
    "            v0.append(code_principal)\n",
    "        elif code_secondary in l and code_secondary not in v0:\n",
    "            v0.append(code_secondary)\n",
    "\n",
    "    return v0\n",
    "def process_rowa(row):\n",
    "    v0  = []\n",
    "    for j in t3:\n",
    "        code_principal = row[j]\n",
    "        code_secondary = row[j.replace('Principal', 'Secondary')]\n",
    "        \n",
    "        # Check for the conditions as per the original script\n",
    "        if code_principal in l and code_secondary in l:\n",
    "            if code_principal != code_secondary and code_principal not in v0 and code_secondary not in v0:\n",
    "                v0.extend([code_principal])\n",
    "            elif code_principal == code_secondary and code_principal not in v0:\n",
    "                v0.append(code_principal)\n",
    "        elif code_principal in l and code_principal not in v0:\n",
    "            v0.append(code_principal)\n",
    "        elif code_secondary in l and code_secondary not in v0:\n",
    "            v0.append(code_secondary)\n",
    "    return v0\n",
    "\n",
    "def process_rowb(row):\n",
    "    v0b = []\n",
    "    for j in t3:\n",
    "        code_principal = row[j]\n",
    "        code_secondary = row[j.replace('Principal', 'Secondary')]\n",
    "        \n",
    "        # Check for the conditions as per the original script\n",
    "        if code_principal in l and code_secondary in l:\n",
    "            if code_principal != code_secondary and code_principal not in v0 and code_secondary not in v0:\n",
    "                v0b.extend([code_secondary])\n",
    "            elif code_principal == code_secondary and code_principal not in v0b:\n",
    "                v0b.append(code_principal)\n",
    "        elif code_principal in l and code_principal not in v0b:\n",
    "            v0b.append(code_principal)\n",
    "        elif code_secondary in l and code_secondary not in v0b:\n",
    "            v0b.append(code_secondary)\n",
    "    return v0b\n",
    "\n",
    "# Apply the function to each row\n",
    "\n",
    "processed_data = df_optimized.apply(process_row, axis=1)\n",
    "processed_data1 = df_optimized.apply(process_row1, axis=1)\n",
    "processed_dataa  = df_optimized.apply(process_rowa, axis=1)\n",
    "processed_datab = df_optimized.apply(process_rowb, axis=1)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "la4 = pd.DataFrame(processed_data.tolist(), index=df_optimized['PatienId']).reset_index()\n",
    "la5 = pd.DataFrame(processed_data1.tolist(), index=df_optimized['PatienId']).reset_index()\n",
    "la6a = pd.DataFrame(processed_dataa.tolist(), index=df_optimized['PatienId']).reset_index()\n",
    "la6b = pd.DataFrame(processed_datab.tolist(), index=df_optimized['PatienId']).reset_index()\n",
    "la6 = pd.concat([la6a,la6b],axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
